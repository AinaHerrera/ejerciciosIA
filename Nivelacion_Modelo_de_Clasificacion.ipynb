{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOX9NnvG8qNgCn8utIErbmQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AinaHerrera/ejerciciosIA/blob/main/Nivelacion_Modelo_de_Clasificacion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "flzyXx6gmqgl"
      },
      "outputs": [],
      "source": [
        "import os, sys, json, numpy as np, pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, classification_report, confusion_matrix,\n",
        "    precision_recall_fscore_support, cohen_kappa_score\n",
        ")\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "FILE_PATH = kagglehub.dataset_download(\"shashanknecrothapa/ames-housing-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", FILE_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-lWirWSqVJP",
        "outputId": "d506026b-294d-46e5-8bbb-73a7a4e245fd"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'ames-housing-dataset' dataset.\n",
            "Path to dataset files: /kaggle/input/ames-housing-dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CUTPOINT = 5\n",
        "if \"Rank\" not in df.columns:\n",
        "    assert \"Overall Cond\" in df.columns, \"Falta 'Overall Cond' para construir Rank.\"\n",
        "    df[\"Rank\"] = np.where(df[\"Overall Cond\"] <= CUTPOINT, \"Low\", \"High\")\n",
        "\n",
        "\n",
        "print(\"Distribución Rank:\\n\", df[\"Rank\"].value_counts().round(3) / len(df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeCfoMc7r8FV",
        "outputId": "f826dd64-c705-4e87-f836-85e135e424d9"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribución Rank:\n",
            " Rank\n",
            "Low     0.621843\n",
            "High    0.378157\n",
            "Name: count, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TARGET_COL = \"Rank\"\n",
        "POSITIVE_CLASS = \"High\"\n",
        "RANDOM_STATE = 42\n",
        "TEST_SIZE = 0.30"
      ],
      "metadata": {
        "id": "0VcjXBKfosot"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43ba3ada",
        "outputId": "32b7b54c-3312-46fd-b4f2-ced451732406"
      },
      "source": [
        "print(\"Columns in the DataFrame:\", df.columns.tolist())"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns in the DataFrame: ['Order', 'PID', 'MS SubClass', 'MS Zoning', 'Lot Frontage', 'Lot Area', 'Street', 'Alley', 'Lot Shape', 'Land Contour', 'Utilities', 'Lot Config', 'Land Slope', 'Neighborhood', 'Condition 1', 'Condition 2', 'Bldg Type', 'House Style', 'Overall Qual', 'Overall Cond', 'Year Built', 'Year Remod/Add', 'Roof Style', 'Roof Matl', 'Exterior 1st', 'Exterior 2nd', 'Mas Vnr Type', 'Mas Vnr Area', 'Exter Qual', 'Exter Cond', 'Foundation', 'Bsmt Qual', 'Bsmt Cond', 'Bsmt Exposure', 'BsmtFin Type 1', 'BsmtFin SF 1', 'BsmtFin Type 2', 'BsmtFin SF 2', 'Bsmt Unf SF', 'Total Bsmt SF', 'Heating', 'Heating QC', 'Central Air', 'Electrical', '1st Flr SF', '2nd Flr SF', 'Low Qual Fin SF', 'Gr Liv Area', 'Bsmt Full Bath', 'Bsmt Half Bath', 'Full Bath', 'Half Bath', 'Bedroom AbvGr', 'Kitchen AbvGr', 'Kitchen Qual', 'TotRms AbvGrd', 'Functional', 'Fireplaces', 'Fireplace Qu', 'Garage Type', 'Garage Yr Blt', 'Garage Finish', 'Garage Cars', 'Garage Area', 'Garage Qual', 'Garage Cond', 'Paved Drive', 'Wood Deck SF', 'Open Porch SF', 'Enclosed Porch', '3Ssn Porch', 'Screen Porch', 'Pool Area', 'Pool QC', 'Fence', 'Misc Feature', 'Misc Val', 'Mo Sold', 'Yr Sold', 'Sale Type', 'Sale Condition', 'SalePrice', 'Rank']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure leak_cols is defined before this cell\n",
        "X = df.drop(columns=[TARGET_COL] + [c for c in leak_cols if c in df.columns])\n",
        "y = df[TARGET_COL].astype(str)"
      ],
      "metadata": {
        "id": "A645wX0Ho4BE"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna(subset=[TARGET_COL]).copy()"
      ],
      "metadata": {
        "id": "mWrl2Tu_o1et"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_features = X.select_dtypes(include=[\"number\"]).columns.tolist()\n",
        "cat_features = X.select_dtypes(include=[\"object\", \"category\", \"bool\"]).columns.tolist()\n",
        "\n",
        "print(f\"Numéricas ({len(num_features)}): {num_features[:10]}{'...' if len(num_features)>10 else ''}\")\n",
        "print(f\"Categóricas ({len(cat_features)}): {cat_features[:10]}{'...' if len(cat_features)>10 else ''}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcGnvBgxo6Ec",
        "outputId": "c9548359-b1d7-4a52-a22a-101a1bb1ab88"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numéricas (38): ['Order', 'PID', 'MS SubClass', 'Lot Frontage', 'Lot Area', 'Overall Qual', 'Year Built', 'Year Remod/Add', 'Mas Vnr Area', 'BsmtFin SF 1']...\n",
            "Categóricas (43): ['MS Zoning', 'Street', 'Alley', 'Lot Shape', 'Land Contour', 'Utilities', 'Lot Config', 'Land Slope', 'Neighborhood', 'Condition 1']...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_transformer = make_pipeline(SimpleImputer(strategy=\"median\"))\n",
        "cat_transformer = make_pipeline(\n",
        "    SimpleImputer(strategy=\"most_frequent\"),\n",
        "    OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        ")\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", num_transformer, num_features),\n",
        "        (\"cat\", cat_transformer, cat_features),\n",
        "    ],\n",
        "    remainder=\"drop\"\n",
        ")"
      ],
      "metadata": {
        "id": "HTLGwydgo8Z0"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=TEST_SIZE, stratify=y, random_state=RANDOM_STATE\n",
        ")"
      ],
      "metadata": {
        "id": "ZSqMERylpDtM"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_clf = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
        "base_pipe = Pipeline(steps=[(\"prep\", preprocessor), (\"clf\", base_clf)])\n",
        "base_pipe.fit(X_train, y_train)\n",
        "y_pred_base = base_pipe.predict(X_test)"
      ],
      "metadata": {
        "id": "X6r3q7LlpHFk"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def per_class_specificity(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calcula Specificity (TN / (TN + FP)) para cada clase.\n",
        "    \"\"\"\n",
        "    labels = np.unique(y_true)\n",
        "    spec = {}\n",
        "    for lbl in labels:\n",
        "        y_true_bin = (y_true == lbl).astype(int)\n",
        "        y_pred_bin = (y_pred == lbl).astype(int)\n",
        "        tn = np.sum((y_true_bin == 0) & (y_pred_bin == 0))\n",
        "        fp = np.sum((y_true_bin == 0) & (y_pred_bin == 1))\n",
        "        spec[lbl] = tn / (tn + fp) if (tn + fp) > 0 else np.nan\n",
        "    return spec\n",
        "\n",
        "def print_eval_block(title, y_true, y_pred):\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(title)\n",
        "    print(\"=\"*70)\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    kappa = cohen_kappa_score(y_true, y_pred)\n",
        "    print(f\"Accuracy: {acc:.3f} | Cohen's kappa: {kappa:.3f}\\n\")\n",
        "\n",
        "    print(\"Reporte por clase (Precision / Recall / F1):\")\n",
        "    print(classification_report(y_true, y_pred, digits=3))\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=np.unique(y_true))\n",
        "    print(\"Matriz de confusión (filas=verdad, columnas=predicción):\")\n",
        "    print(pd.DataFrame(cm, index=[f\"true_{l}\" for l in np.unique(y_true)],\n",
        "                          columns=[f\"pred_{l}\" for l in np.unique(y_true)]))\n",
        "\n",
        "    spec = per_class_specificity(y_true, y_pred)\n",
        "    print(\"\\nSpecificity por clase:\")\n",
        "    print(pd.Series(spec).round(3))\n",
        "\n",
        "\n",
        "print_eval_block(\"EVALUACIÓN - MODELO BASE\", y_test, y_pred_base)\n",
        "\n",
        "\n",
        "disp = ConfusionMatrixDisplay.from_predictions(y_test, y_pred_base)\n",
        "plt.title(\"Confusion Matrix - Base\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"confusion_matrix_base.png\", dpi=150)\n",
        "plt.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7H-ehVRgpKFF",
        "outputId": "e1b1d098-6818-436a-8ad3-bd215375d249"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "EVALUACIÓN - MODELO BASE\n",
            "======================================================================\n",
            "Accuracy: 1.000 | Cohen's kappa: 1.000\n",
            "\n",
            "Reporte por clase (Precision / Recall / F1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        High      1.000     1.000     1.000       332\n",
            "         Low      1.000     1.000     1.000       547\n",
            "\n",
            "    accuracy                          1.000       879\n",
            "   macro avg      1.000     1.000     1.000       879\n",
            "weighted avg      1.000     1.000     1.000       879\n",
            "\n",
            "Matriz de confusión (filas=verdad, columnas=predicción):\n",
            "           pred_High  pred_Low\n",
            "true_High        332         0\n",
            "true_Low           0       547\n",
            "\n",
            "Specificity por clase:\n",
            "High    1.0\n",
            "Low     1.0\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bEyKZM3spK4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    \"clf__criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
        "    \"clf__max_depth\": [None, 3, 5, 10],\n",
        "    \"clf__min_samples_split\": [2, 10, 20],\n",
        "    \"clf__min_samples_leaf\": [1, 5, 10],\n",
        "    \"clf__class_weight\": [None, \"balanced\"]\n",
        "}\n",
        "pipe = Pipeline(steps=[(\"prep\", preprocessor),\n",
        "                      (\"clf\", DecisionTreeClassifier(random_state=RANDOM_STATE))])\n",
        "\n",
        "scoring = {\n",
        "    \"accuracy\": \"accuracy\",\n",
        "    \"precision_macro\": \"precision_macro\",\n",
        "    \"recall_macro\": \"recall_macro\",\n",
        "    \"f1_macro\": \"f1_macro\"\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    estimator=pipe,\n",
        "    param_grid=param_grid,\n",
        "    scoring=scoring,\n",
        "    refit=\"f1_macro\",\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "grid.fit(X_train, y_train)\n",
        "print(\"\\nMejores hiperparámetros (refit=f1_macro):\")\n",
        "print(grid.best_params_)\n",
        "print(f\"Mejor puntaje CV (f1_macro): {grid.best_score_:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzLzaE6tpNM0",
        "outputId": "0cc8c02d-d8b4-4e80-c3a0-90682fd15479"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
            "\n",
            "Mejores hiperparámetros (refit=f1_macro):\n",
            "{'clf__class_weight': None, 'clf__criterion': 'gini', 'clf__max_depth': None, 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 20}\n",
            "Mejor puntaje CV (f1_macro): 0.769\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv_df = pd.DataFrame(grid.cv_results_)\n",
        "cols_keep = [c for c in cv_df.columns if c.startswith(\"mean_test_\")] + \\\n",
        "            [c for c in cv_df.columns if c.startswith(\"param_\")]\n",
        "cv_top = cv_df[cols_keep].sort_values(\"mean_test_f1_macro\", ascending=False).head(10)\n",
        "cv_top.to_csv(\"cv_results_top10.csv\", index=False)\n",
        "print(\"\\nTop 10 combinaciones (por f1_macro):\")\n",
        "print(cv_top)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8tVslIkpQpc",
        "outputId": "4c280483-88c7-437e-ab15-90188d6812a5"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 10 combinaciones (por f1_macro):\n",
            "     mean_test_accuracy  mean_test_precision_macro  mean_test_recall_macro  \\\n",
            "5              0.782534                   0.769155                0.769088   \n",
            "65             0.776697                   0.766182                0.765668   \n",
            "101            0.776697                   0.766182                0.765668   \n",
            "79             0.776691                   0.763350                0.763395   \n",
            "44             0.776691                   0.763350                0.763395   \n",
            "43             0.776691                   0.763350                0.763395   \n",
            "42             0.776691                   0.763350                0.763395   \n",
            "80             0.776691                   0.763350                0.763395   \n",
            "78             0.776691                   0.763350                0.763395   \n",
            "7              0.775223                   0.761355                0.764222   \n",
            "\n",
            "     mean_test_f1_macro param_clf__class_weight param_clf__criterion  \\\n",
            "5              0.768920                    None                 gini   \n",
            "65             0.763112                    None              entropy   \n",
            "101            0.763112                    None             log_loss   \n",
            "79             0.762762                    None             log_loss   \n",
            "44             0.762762                    None              entropy   \n",
            "43             0.762762                    None              entropy   \n",
            "42             0.762762                    None              entropy   \n",
            "80             0.762762                    None             log_loss   \n",
            "78             0.762762                    None             log_loss   \n",
            "7              0.762443                    None                 gini   \n",
            "\n",
            "    param_clf__max_depth  param_clf__min_samples_leaf  \\\n",
            "5                   None                            5   \n",
            "65                    10                            1   \n",
            "101                   10                            1   \n",
            "79                  None                           10   \n",
            "44                  None                           10   \n",
            "43                  None                           10   \n",
            "42                  None                           10   \n",
            "80                  None                           10   \n",
            "78                  None                           10   \n",
            "7                   None                           10   \n",
            "\n",
            "     param_clf__min_samples_split  \n",
            "5                              20  \n",
            "65                             20  \n",
            "101                            20  \n",
            "79                             10  \n",
            "44                             20  \n",
            "43                             10  \n",
            "42                              2  \n",
            "80                             20  \n",
            "78                              2  \n",
            "7                              10  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = grid.best_estimator_\n",
        "y_pred_best = best_model.predict(X_test)\n",
        "print_eval_block(\"EVALUACIÓN - MEJOR MODELO (GridSearchCV)\", y_test, y_pred_best)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuIAjEaopSmk",
        "outputId": "e724644d-c096-46de-a061-4a93bae1dc5b"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "EVALUACIÓN - MEJOR MODELO (GridSearchCV)\n",
            "======================================================================\n",
            "Accuracy: 0.766 | Cohen's kappa: 0.496\n",
            "\n",
            "Reporte por clase (Precision / Recall / F1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        High      0.701     0.663     0.681       332\n",
            "         Low      0.802     0.828     0.815       547\n",
            "\n",
            "    accuracy                          0.766       879\n",
            "   macro avg      0.751     0.745     0.748       879\n",
            "weighted avg      0.764     0.766     0.764       879\n",
            "\n",
            "Matriz de confusión (filas=verdad, columnas=predicción):\n",
            "           pred_High  pred_Low\n",
            "true_High        220       112\n",
            "true_Low          94       453\n",
            "\n",
            "Specificity por clase:\n",
            "High    0.828\n",
            "Low     0.663\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "disp = ConfusionMatrixDisplay.from_estimator(best_model, X_test, y_test)\n",
        "plt.title(\"Confusion Matrix - Best\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"confusion_matrix_best.png\", dpi=150)\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "CW6Vobt0pUQs"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_unique = np.unique(y_train)\n",
        "if len(labels_unique) == 2 and hasattr(best_model.named_steps[\"clf\"], \"predict_proba\"):\n",
        "    proba = best_model.predict_proba(X_test)\n",
        "    classes_ = best_model.named_steps[\"clf\"].classes_\n",
        "    if POSITIVE_CLASS not in classes_:\n",
        "        print(f\"\\n[Aviso] POSITIVE_CLASS '{POSITIVE_CLASS}' no está en {classes_}. Se usará classes_[1].\")\n",
        "        pos_idx = 1\n",
        "        pos_label = classes_[pos_idx]\n",
        "    else:\n",
        "        pos_idx = list(classes_).index(POSITIVE_CLASS)\n",
        "        pos_label = POSITIVE_CLASS\n",
        "\n",
        "    other_label = [c for c in classes_ if c != pos_label][0]\n",
        "    thresholds = np.linspace(0.20, 0.80, 13)\n",
        "\n",
        "    rows = []\n",
        "    for thr in thresholds:\n",
        "        y_pred_thr = np.where(proba[:, pos_idx] >= thr, pos_label, other_label)\n",
        "        # Métricas para la clase positiva\n",
        "        p, r, f1, _ = precision_recall_fscore_support(\n",
        "            y_test, y_pred_thr, labels=[pos_label], average=\"binary\", pos_label=pos_label, zero_division=0\n",
        "        )\n",
        "        acc = accuracy_score(y_test, y_pred_thr)\n",
        "        rows.append({\"threshold\": round(thr,3), \"accuracy\": acc, \"precision_pos\": p, \"recall_pos\": r, \"f1_pos\": f1})\n",
        "\n",
        "    thr_df = pd.DataFrame(rows).sort_values([\"f1_pos\",\"recall_pos\"], ascending=False)\n",
        "    thr_df.to_csv(\"threshold_tuning.csv\", index=False)\n",
        "    print(\"\\nAjuste de umbral para la clase positiva \"\n",
        "          f\"('{pos_label}') - ordenado por F1 y Recall (top 8):\")\n",
        "    print(thr_df.head(8).round(3))\n",
        "else:\n",
        "    print(\"\\n[Aviso] Salto ajuste de umbral (no binario o el clasificador no expone predict_proba).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUJHjEk3pWHE",
        "outputId": "fb4fee5c-fbf6-4603-8285-965cea78f713"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ajuste de umbral para la clase positiva ('High') - ordenado por F1 y Recall (top 8):\n",
            "   threshold  accuracy  precision_pos  recall_pos  f1_pos\n",
            "0       0.20     0.741          0.619       0.816   0.704\n",
            "1       0.25     0.745          0.630       0.786   0.700\n",
            "3       0.35     0.761          0.669       0.729   0.697\n",
            "4       0.40     0.758          0.669       0.711   0.689\n",
            "2       0.30     0.743          0.635       0.750   0.688\n",
            "5       0.45     0.765          0.690       0.684   0.687\n",
            "6       0.50     0.766          0.701       0.663   0.681\n",
            "7       0.55     0.763          0.705       0.642   0.672\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(best_model, \"decision_tree_best.joblib\")\n",
        "print(\"\\nArtefactos guardados:\")\n",
        "for fp in [\"confusion_matrix_base.png\", \"confusion_matrix_best.png\",\n",
        "           \"cv_results_top10.csv\", \"threshold_tuning.csv\",\n",
        "           \"decision_tree_best.joblib\"]:\n",
        "    if os.path.exists(fp):\n",
        "        print(\" -\", fp)\n",
        "\n",
        "print(\"\\nFIN ✅\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70mLR4HJpZt8",
        "outputId": "0412ecde-abb2-4995-f4e4-69b7b928eff0"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Artefactos guardados:\n",
            " - confusion_matrix_base.png\n",
            " - confusion_matrix_best.png\n",
            " - cv_results_top10.csv\n",
            " - threshold_tuning.csv\n",
            " - decision_tree_best.joblib\n",
            "\n",
            "FIN ✅\n"
          ]
        }
      ]
    }
  ]
}